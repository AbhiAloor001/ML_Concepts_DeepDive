{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q : In prediction problems that involves several predictor variables and a target variable, what are our assumptions?\n",
    "\n",
    "A : predictors : $X_1, X_2, X_3, \\dots, X_p$, target : $Y$\n",
    "\n",
    "* there is some unknown relation between predictors and target :\n",
    "$$Y = f(X) + \\epsilon$$\n",
    "* f is a fixed but unknown function of the predictors\n",
    "* $\\epsilon$ capturess the deviations in Y being f(X) due to some unforeseen/ out-of-our-control/natural circumstances or reasons\n",
    "* $\\epsilon$ is a random error term that has mean 0\n",
    "* $\\epsilon$ and predictors are independent\n",
    "* f represents the systematic information that X provides about Y "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q : In prediction problems, what are we trying to do?\n",
    "\n",
    "A : We estimate f, so that we can predict Y for any given X using the estimated f."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q : The accuracy of the predictions of Y depends on _____ and ______ errors.\n",
    "\n",
    "* irreducible and reducible"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q : What does reducible error in prediction mean?\n",
    "\n",
    "A : Our estimate of the true underlying systematic relation f may not be same as f. This difference between true f and estimated f is reducible error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q : What about irreducible error in prediction?\n",
    "\n",
    "A : Even if we capture the true systematic relation between X and Y, there may happen some natural out of the control deviations which are random. This is because Y is also a function of $\\epsilon$, which, by definition, cannot be predicted using X. Such deviations are called irreducible error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q : Irreducible error is always non-zero. What might be the possible reasons ?\n",
    "\n",
    "* The quantity $\\epsilon$ may contain unmeasured variables that are useful in predicting Y\n",
    "* $\\epsilon$ may also contain unmeasurable variation. For example, the risk of an adverse reaction might vary for a given patient on a given day, depending on manufacturing variation in the drug itself or the patientâ€™s general feeling of well-being on that day.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q : What is over-fitting?\n",
    "\n",
    "* When a given method yields a small training MSE but a large test MSE, we are said to be overfitting the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q : Why does over-fitting happen?\n",
    "\n",
    "* This happens because our statistical learning procedure is working too hard to find patterns in the training data, and may be picking up some patterns that are just caused by random chance rather than by true properties of the unknown function f."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q : Explain the notation :\n",
    "$$E[(y_0 - \\hat{f}(x_0))^2]$$\n",
    "\n",
    "* defines the expected test MSE at $x_0$\n",
    "* refers to the average test MSE that we would obtain if we repeatedly\n",
    "estimated f using a large number of training sets, and tested each estimate at $x_0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q : Suppose, we are given a set of test data points. How to compute the overall test MSE based on this set of points?\n",
    "\n",
    "A : by averaging $E[(y_0-\\hat{f}(x_0))^2]$ over all possible values of $x_0$ in the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q : For a statistical learning method and a given test data point write down the expected test MSE in terms of Bias and variance.\n",
    "\n",
    "* $$E[(y_0 - \\hat{f}(x_0))^2] = Var(\\hat{f}(x_0)) + [Bias(\\hat{f}(x_0))]^2 + Var(\\epsilon)$$\n",
    "\n",
    "* in order to minimize the expected test error, we need to select a statistical learning method that simultaneously achieves low variance and low bias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q : What is the difference of a statistical learning method?\n",
    "\n",
    "A : \n",
    "* the amount by which $\\hat{f}$ would change if we estimated it using a different training data set.\n",
    "* Since the training data are used to fit the statistical learning method, different training data sets will result in a different $\\hat{f}$. \n",
    "* But ideally the estimate for f should not vary too much between training sets. \n",
    "* However, if a method has high variance then small changes in the training data can result in large changes in $\\hat{f}$.\n",
    "\n",
    "$$Var = E[(\\hat{f}-E(\\hat{f}))^2]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q : What is bias of a statistical learning method?\n",
    "\n",
    "A :\n",
    "* difference between the true model and the average of all possible model estimates using that particular learning method\n",
    "* $$Bias = f - E(\\hat{f})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q : "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
